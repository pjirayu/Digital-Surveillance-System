{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"3_3comparsion_of_different_channel_on_feature_map_D10907801.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"code","metadata":{"id":"hRvmgU9G4wHh","executionInfo":{"status":"ok","timestamp":1606652760545,"user_tz":-480,"elapsed":1679,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import cv2\n","from torchvision import models\n","from torch.autograd import Variable\n","from torchsummary import summary\n","\n","# Define whether to use GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def save_checkpoint(state, save_dir, filename='checkpoint.pth'):\n","    save_name = save_dir + '_{}'.format(filename)\n","    torch.save(state, save_name)\n","########################################################################\n","# The output of torchvision datasets are PILImage images of range [0, 1].\n","# We transform them to Tensors of normalized range [-1, 1].\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        # calculate same padding:\n","        # (w - k + 2*p)/s + 1 = o\n","        # => p = (s(o-1) - w + k)/2\n","\n","        self.feature = nn.Sequential(\n","            nn.Conv2d(in_channels=3,\n","                      out_channels=64,\n","                      kernel_size=(3, 3),\n","                      stride=(1, 1),\n","                      # (1(32-1)- 32 + 3)/2 = 1\n","                      padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=64,\n","                      out_channels=64,\n","                      kernel_size=(3, 3),\n","                      stride=(1, 1),\n","                      padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(2, 2),\n","                         stride=(2, 2)),\n","                         \n","            nn.Conv2d(in_channels=64,\n","                      out_channels=256,\n","                      kernel_size=(3, 3),\n","                      stride=(1, 1),\n","                      padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=256,\n","                      out_channels=256,\n","                      kernel_size=(3, 3),\n","                      stride=(1, 1),\n","                      padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(2, 2),\n","                         stride=(2, 2)),\n","            nn.Conv2d(in_channels=256,\n","                      out_channels=256,\n","                      kernel_size=(3, 3),\n","                      stride=(1, 1),\n","                      padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=256,\n","                      out_channels=256,\n","                      kernel_size=(3, 3),\n","                      stride=(1, 1),\n","                      padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=256,\n","                      out_channels=256,\n","                      kernel_size=(3, 3),\n","                      stride=(1, 1),\n","                      padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(2, 2),\n","                         stride=(2, 2)),\n","        #     nn.Conv2d(in_channels=256,\n","        #               out_channels=1024,\n","        #               kernel_size=(3, 3),\n","        #               stride=(1, 1),\n","        #               padding=1),\n","        #     nn.BatchNorm2d(1024),\n","        #     nn.ReLU(),\n","        #     nn.Conv2d(in_channels=1024,\n","        #               out_channels=1024,\n","        #               kernel_size=(3, 3),\n","        #               stride=(1, 1),\n","        #               padding=1),\n","        #     nn.BatchNorm2d(1024),\n","        #     nn.ReLU(),\n","        #     nn.Conv2d(in_channels=1024,\n","        #               out_channels=1024,\n","        #               kernel_size=(3, 3),\n","        #               stride=(1, 1),\n","        #               padding=1),\n","        #     nn.BatchNorm2d(1024),\n","        #     nn.ReLU(),\n","        #     nn.MaxPool2d(kernel_size=(2, 2),\n","        #                  stride=(2, 2)),\n","        #     nn.Conv2d(in_channels=1024,\n","        #               out_channels=2048,\n","        #               kernel_size=(3, 3),\n","        #               stride=(1, 1),\n","        #               padding=1),\n","        #     nn.BatchNorm2d(2048),\n","        #     nn.ReLU(),\n","        #     nn.Conv2d(in_channels=2048,\n","        #               out_channels=2048,\n","        #               kernel_size=(3, 3),\n","        #               stride=(1, 1),\n","        #               padding=1),\n","        #     nn.BatchNorm2d(2048),\n","        #     nn.ReLU(),\n","        #     nn.Conv2d(in_channels=2048,\n","        #               out_channels=2048,\n","        #               kernel_size=(3, 3),\n","        #               stride=(1, 1),\n","        #               padding=1),\n","        #     nn.BatchNorm2d(2048),\n","        #     nn.ReLU(),\n","        #     nn.MaxPool2d(kernel_size=(2, 2),\n","        #                  stride=(2, 2))                         \n","         )\n","\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(256, 128),\n","            nn.ReLU(True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(128, 64),\n","            nn.ReLU(True),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(64, 10),\n","        )\n","\n","        for m in self.modules():\n","            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n","                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n","\n","                if m.bias is not None:\n","                    m.bias.detach().zero_()\n","\n","\n","\n","    def forward(self, x):\n","\n","        x = self.feature(x)\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","\n","        return x\n","\n","def preprocess_image(cv2im, resize_im=True):\n","\n","    # Resize image\n","    if resize_im:\n","        cv2im = cv2.resize(cv2im, (64, 64))\n","    im_as_arr = np.float32(cv2im)\n","    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])\n","    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n","    # Normalize the channels\n","    for channel, _ in enumerate(im_as_arr):\n","        im_as_arr[channel] /= 255\n","    # Convert to float tensor\n","    im_as_ten = torch.from_numpy(im_as_arr).float()\n","    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n","    im_as_ten.unsqueeze_(0)\n","    # Convert to Pytorch variable\n","    im_as_var = Variable(im_as_ten, requires_grad=True)\n","    return im_as_var\n","\n","\n","\n","\n","\n","class FeatureVisualization():\n","    def __init__(self,img_path,selected_layer):\n","        self.img_path=img_path\n","        self.selected_layer=selected_layer\n","        # Load pretrained model\n","        net = Net().to(device)\n","        checkpoint = torch.load('./test_epoch1_checkpoint.pth')\n","        net.load_state_dict(checkpoint['net'])\n","        self.pretrained_model = net.feature\n","        #self.pretrained_model = net.features\n","        self.pretrained_model2 = net\n","\n","    def process_image(self):\n","        img=cv2.imread(self.img_path)\n","        img=preprocess_image(img)\n","        return img\n","\n","    def get_feature(self):\n","        # Image  preprocessing\n","        input=self.process_image()\n","        #print(\"input.shape:{}\".format(input.shape))\n","        x=input.to(device)\n","        for index,layer in enumerate(self.pretrained_model):\n","            x=layer(x)\n","            #print(\"x:{}\".format(x.shape))\n","            if (index == self.selected_layer):\n","                return x\n","\n","    def get_single_feature(self):\n","        # Get the feature map\n","\n","        features=self.get_feature()\n","        #print(features.shape)\n","        feature=features[:,0,:,:]\n","        feature=feature.view(feature.shape[1],feature.shape[2])\n","\n","        #print(\"feature\")\n","        #print(feature.shape)\n","        return feature\n","\n","    def get_multi_feature(self):\n","        # Get the feature map\n","        features=self.get_feature()\n","        #print(features.shape)\n","        result_path = './feat_first_' + str(self.selected_layer)\n","\n","        if not os.path.exists(result_path):\n","            os.makedirs(result_path)\n","        print(\"On layer:{}, We can get the {} feature maps\".format(self.selected_layer,features.shape[1]))    \n","        #print(features.shape[1])\n","        for i in range(features.shape[1]):\n","            feature=features[:,i,:,:]\n","            feature=feature.view(feature.shape[1],feature.shape[2])\n","            feature = feature.cpu().data.numpy()\n","            feature = 1.0 / (1 + np.exp(-1 * feature))\n","            feature = np.round(feature * 255)\n","            save_name = result_path + '/' + str(i) + '.jpg'\n","            cv2.imwrite(save_name, feature)\n","    def get_multi_feature1(self):\n","        # Get the feature map\n","        features=self.get_feature()\n","        #print(features.shape)\n","        result_path = './feat_second_' + str(self.selected_layer)\n","\n","        if not os.path.exists(result_path):\n","            os.makedirs(result_path)\n","        print(\"On layer:{}, We can get the {} feature maps\".format(self.selected_layer,features.shape[1]))    \n","        #print(features.shape[1])\n","        for i in range(features.shape[1]):\n","            feature=features[:,i,:,:]\n","            feature=feature.view(feature.shape[1],feature.shape[2])\n","            feature = feature.cpu().data.numpy()\n","            feature = 1.0 / (1 + np.exp(-1 * feature))\n","            feature = np.round(feature * 255)\n","            save_name = result_path + '/' + str(i) + '.jpg'\n","            cv2.imwrite(save_name, feature)        \n","\n","\n","    def save_feature_to_img1(self):\n","        #to numpy\n","        feature=self.get_single_feature()\n","        self.get_multi_feature()\n","        feature=feature.cpu().data.numpy()\n","\n","        #use sigmod to [0,1]\n","        # print(feature[0])\n","        feature= 1.0/(1+np.exp(-1*feature))\n","\n","        # to [0,255]\n","        feature=np.round(feature*255)\n","        #print(self.selected_layer)\n","        save_name = './feat_first' + str(self.selected_layer) + '.jpg'\n","        cv2.imwrite(save_name, feature)\n","    def save_feature_to_img2(self):\n","        #to numpy\n","        feature=self.get_single_feature()\n","        self.get_multi_feature1()\n","        feature=feature.cpu().data.numpy()\n","\n","        #use sigmod to [0,1]\n","        # print(feature[0])\n","        feature= 1.0/(1+np.exp(-1*feature))\n","\n","        # to [0,255]\n","        feature=np.round(feature*255)\n","        #print(self.selected_layer)\n","        save_name = './feat_second' + str(self.selected_layer) + '.jpg'\n","        cv2.imwrite(save_name, feature)    \n","\n","    def plot_probablity(self,outputs):\n","\n","        outputs = outputs.cpu().data.numpy()\n","        outputs = np.ndarray.tolist(outputs)\n","\n","        x = range(0, 1000)\n","        plt.bar(x, outputs[0])\n","        plt.xlabel(\"Class\")\n","        plt.ylabel(\"Probablity\")\n","        plt.title(\"Image classifier\")\n","        plt.show()\n","\n","\n","    def predict(self):\n","        input=self.process_image().cuda()\n","        outputs = self.pretrained_model2(input)\n","\n","        return outputs\n","\n","\n","\n","    \n","\n","\n","\n","\n","    \n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3DbO-wS_QyN","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1606652783913,"user_tz":-480,"elapsed":2515,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}},"outputId":"5171873e-1aee-4438-a943-7455a13d2fd8"},"source":["if __name__==\"__main__\":\n","    def imshow(img):\n","        img = img / 2 + 0.5  # unnormalize\n","        npimg = img.cpu().numpy()\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","        plt.show()\n","\n","\n","    transform = transforms.Compose(\n","        [transforms.Resize(64),transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                              shuffle=True, num_workers=2)\n","\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                           download=True, transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                             shuffle=False, num_workers=2)\n","\n","\n","\n","\n","\n","\n","    net = Net().to(device)\n"," \n","    #checkpoint = torch.load('./test_epoch1_checkpoint.pth')\n","    #net.load_state_dict(checkpoint['net'])\n","    \n","    print(net)\n","    \n","    # %debug\n","    # summary(net,(3, 32, 32))\n","    \n","    ########################################################################\n","    # 3. Define a Loss function and optimizer\n","    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","    # Let's use a Classification Cross-Entropy loss and Adam with momentum.\n","\n","\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","    ########################################################################\n","    # 4. Train the network\n","    # ^^^^^^^^^^^^^^^^^^^^\n","    #\n","    # This is when things start to get interesting.\n","    # We simply have to loop over our data iterator, and feed the inputs to the\n","    # network and optimize.\n","\n","    for epoch in range(3):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            \n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 2000 == 1999:    # print every 2000 mini-batches\n","        \n","                print(\"Epoch : {} steps : {} Training Loss : {}\".format(epoch + 1, i + 1, running_loss / 2000) )\n","                running_loss = 0.0\n","        save_checkpoint({'net':net.state_dict()}, 'test_epoch{}'.format(epoch+1))        \n","\n","    print('Finished Training')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Net(\n","  (feature): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU()\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU()\n","    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU()\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU()\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU()\n","    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=256, out_features=128, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=128, out_features=64, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=64, out_features=10, bias=True)\n","  )\n",")\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f92afe9f693c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-7bc7a52ec585>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"]}]},{"cell_type":"code","metadata":{"id":"6uJDA2XcJ3Gd","executionInfo":{"status":"aborted","timestamp":1606652766321,"user_tz":-480,"elapsed":7441,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["    from google.colab import files\n","    from io import BytesIO\n","    from PIL import Image\n","\n","    uploaded = files.upload()\n","    im1 = Image.open(BytesIO(uploaded['Nebula.jpg']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GWTo_7g4-3ow","executionInfo":{"status":"aborted","timestamp":1606652766322,"user_tz":-480,"elapsed":7438,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["    myClass=FeatureVisualization('Highsierra.jpg',2)\n","    Compare=FeatureVisualization('Nebula.jpg',2)    \n","    print(myClass.pretrained_model2)\n","\n","    #image1 = cv2.imread('./Highsierra.jpg')\n","    #image2 = cv2.imread('./Nebula.jpg')\n","    #myClass1 = cv2.resize(image1, 64)\n","    #Compare1 = cv2.resize(image2, 64)\n","\n","    myClass.save_feature_to_img1()\n","    Compare.save_feature_to_img2()\n","    # print(\"The first picture classification predict:\")\n","    myClass_vector = myClass.predict()\n","    # print(\"The second picture classification predict:\")\n","    Compare_vector = Compare.predict()\n","    #Define cosine similarity\n","    cos= nn.CosineSimilarity(dim=1)\n","    #Define Euclidean distance\n","    euclidean_dist = torch.dist(myClass_vector,Compare_vector,p=2)\n","    cosine_dist = cos(myClass_vector,Compare_vector)\n","    print(\"Verification:\")\n","    if cosine_dist > 0.4:\n","        print(\"They are the same!\")\n","        print(\"Their cosine_similarity:{}\".format(cosine_dist))\n","    else:\n","        print(\"They are not the same!\")\n","        print(\"Their cosine_similarity:{}\".format(cosine_dist))\n","       \n","    print(\"Their euclidean_dist:{}\".format(euclidean_dist))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9JE2yUeDhEj","executionInfo":{"status":"aborted","timestamp":1606652766323,"user_tz":-480,"elapsed":7435,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":[""],"execution_count":null,"outputs":[]}]}