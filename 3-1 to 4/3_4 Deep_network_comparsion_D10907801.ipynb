{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_4 Deep_network_comparsion_D10907801.ipynb","provenance":[{"file_id":"1aLA1NmRMxXjTuFhbnxuxt2OHBjMR4aiu","timestamp":1603286901344}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"puqu2f6CdByU","executionInfo":{"status":"ok","timestamp":1606659828828,"user_tz":-480,"elapsed":4318,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from torchvision import models\n","from torchsummary import summary\n","from torch import add"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SFhcPhlgNGJ","executionInfo":{"status":"ok","timestamp":1606659828834,"user_tz":-480,"elapsed":4312,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["def save_checkpoint(state, save_dir, filename='checkpoint.pth'):\n","    save_name = save_dir + '_{}'.format(filename)\n","    torch.save(state, save_name)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"1WkFgLQ6mYBM","executionInfo":{"status":"ok","timestamp":1606659828835,"user_tz":-480,"elapsed":4306,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, inchannel, outchannel, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.left = nn.Sequential(\n","            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel)\n","        )\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or inchannel != outchannel:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(outchannel)\n","            )\n","\n","    def forward(self, x):\n","        out = self.left(x)\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, ResidualBlock, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.inchannel = 64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)\n","        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=1)\n","        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=1)\n","        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=1)\n","        self.fc = nn.Linear(2048, num_classes)\n","\n","    def make_layer(self, block, channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.inchannel, channels, stride))\n","            self.inchannel = channels\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","def ResNet18():\n","\n","    return ResNet(ResidualBlock)\n","\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOfDJqmxmgHt","executionInfo":{"status":"ok","timestamp":1606659828837,"user_tz":-480,"elapsed":4301,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),)\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),)\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),)\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),)\n","        self.conv5 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),)\n","        self.conv6 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),)\n","        self.conv7 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),)\n","        self.conv8 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),)\n","        self.conv9 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),)\n","        self.conv10 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),)\n","        #self.conv11 = nn.Sequential(\n","            #nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            #nn.BatchNorm2d(128),\n","            #nn.ReLU(),\n","        #)\n","        # self.conv12 = nn.Sequential(\n","            # nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n","            # nn.ReLU(),\n","        # )\n","        # self.conv13 = nn.Sequential(\n","            # nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False), \n","            # nn.ReLU(),\n","        # )\n","        # self.conv14 = nn.Sequential(\n","            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False), \n","            # nn.ReLU(),\n","        # )\n","        # self.conv15 = nn.Sequential(\n","            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False), \n","            # nn.ReLU(),\n","        # )\n","        # self.conv16 = nn.Sequential(\n","            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False), \n","            # nn.ReLU(),\n","        # )\n","        # self.conv17 = nn.Sequential(\n","            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False), \n","            # nn.ReLU(),\n","        # )\n","        \n","        self.pool1 = nn.MaxPool2d((2,2))\n","      \n","        \n","        self.fc1 = nn.Sequential(nn.Linear(128*16*16, 128),\n","                    nn.Dropout(0.25),\n","                    nn.BatchNorm1d(128),\n","                    nn.ReLU(),) \n","        self.fc2 = nn.Sequential(nn.Linear(128, 32),\n","                    nn.Dropout(0.25),\n","                    nn.BatchNorm1d(32),\n","                    nn.ReLU(),)  \n","        self.fc3 = nn.Linear(32, 10)       \n","                             \n","       \n","    def forward(self, x):\n","        x = self.conv1(x) \n","        x = self.conv2(x) \n","        x = self.conv3(x) \n","        x = self.conv4(x) \n","        x = self.conv5(x) \n","        x = self.conv6(x) \n","        x = self.conv7(x)\n","        x = self.conv8(x)\n","        x = self.conv9(x)\n","        x = self.conv10(x)\n","        x = self.pool1(x)\n","        \n","        x = x.view(-1, 128*16*16)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","       \n","        return x"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAI4mcMvGzwG","executionInfo":{"status":"ok","timestamp":1606659831353,"user_tz":-480,"elapsed":6808,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":["#vgg16 model\n","# state_dict = torch.hub.load_state_dict_from_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')\n","vgg16 = models.vgg16(pretrained = False, progress=True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhcssc1Hdull","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1606659907060,"user_tz":-480,"elapsed":3073,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}},"outputId":"6c729ef8-d8c0-4db2-a6c9-5bd24c145324"},"source":["# Define whether to use GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","########################################################################\n","# The output of torchvision datasets are PILImage images of range [0, 1].\n","# We transform them to Tensors of normalized range [-1, 1].\n","\n","if __name__==\"__main__\":\n","    def imshow(img):\n","        img = img / 2 + 0.5  # unnormalize\n","        npimg = img.cpu().numpy()\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","        plt.show()\n","\n","\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                              shuffle=True, num_workers=8)\n","\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                           download=True, transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                             shuffle=False, num_workers=8)\n","\n","    classes = ('plane', 'car', 'bird', 'cat',\n","               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","\n","\n","    \n","    # net = Net().to(device)\n","    net = ResNet18().to(device)\n","    # net = vgg16().to(device)\n","    print(net)\n","\n","    netsum=Net()\n","    # summary(net,(3, 32, 32))\n","    \n","    ########################################################################\n","    # 3. Define a Loss function and optimizer\n","    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","    # Let's use a Classification Cross-Entropy loss and SGD with momentum.\n","\n","\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","    ########################################################################\n","    # 4. Train the network\n","    # ^^^^^^^^^^^^^^^^^^^^\n","    #\n","    # This is when things start to get interesting.\n","    # We simply have to loop over our data iterator, and feed the inputs to the\n","    # network and optimize.\n","\n","    for epoch in range(5):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            \n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 2000 == 1999:    # print every 2000 mini-batches\n","        \n","                print(\"Epoch : {} steps : {} Training Loss : {}\".format(epoch + 1, i + 1, running_loss / 2000) )\n","                running_loss = 0.0\n","        save_checkpoint({'net':net.state_dict()}, 'test_epoch{}'.format(epoch+1))        \n","\n","    print('Finished Training')\n","\n","    ########################################################################\n","    # 5. Test the network on the test data\n","    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","    #\n","    # We have trained the network for 2 passes over the training dataset.\n","    # But we need to check if the network has learnt anything at all.\n","    #\n","    # We will check this by predicting the class label that the neural network\n","    # outputs, and checking it against the ground-truth. If the prediction is\n","    # correct, we add the sample to the list of correct predictions.\n","    #\n","    # Okay, first step. Let us display an image from the test set to get familiar.\n","\n","    dataiter = iter(testloader)\n","    images, labels = dataiter.next()\n","    images, labels = images.to(device), labels.to(device)\n","    #\n","    # # print images\n","    imshow(torchvision.utils.make_grid(images))\n","    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n","    #\n","    # ########################################################################\n","    # # Okay, now let us see what the neural network thinks these examples above are:\n","    #\n","    outputs = net(images)\n","    #\n","    # ########################################################################\n","    # # The outputs are energies for the 10 classes.\n","    # # The higher the energy for a class, the more the network\n","    # # thinks that the image is of the particular class.\n","    # # So, let's get the index of the highest energy:\n","    _, predicted = torch.max(outputs, 1)\n","    #\n","    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n","                                  for j in range(4)))\n","\n","    ########################################################################\n","    # The results seem pretty good.\n","    #\n","    # Let us look at how the network performs on the whole dataset.\n","\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images, labels =images.to(device), labels.to(device)\n","            outputs = net(images)\n","            \n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy : %d %%' % (100 * correct / total))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","ResNet(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (layer1): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",")\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-bf02471520cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-6f954f9b4f2c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"]}]},{"cell_type":"code","metadata":{"id":"QgBFBIu7dmg0","executionInfo":{"status":"aborted","timestamp":1606659890570,"user_tz":-480,"elapsed":66013,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFs_APXHV7ksCF_kOwXartjBd4wWdMk4GlyP7XEw=s64","userId":"15677881651496530626"}}},"source":[""],"execution_count":null,"outputs":[]}]}